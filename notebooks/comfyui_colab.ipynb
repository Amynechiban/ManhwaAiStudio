{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aaaaaaaaaa"
      },
      "source": [
        "Git clone the repo and install the requirements. (ignore the pip errors about protobuf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bbbbbbbbbb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8e55aaf-5217-44db-a436-aef5b5d7f393"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounting Google Drive...\n",
            "/\n",
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive\n",
            "-= Initial setup ComfyUI =-\n",
            "Cloning into 'ComfyUI'...\n",
            "remote: Enumerating objects: 20476, done.\u001b[K\n",
            "remote: Counting objects: 100% (132/132), done.\u001b[K\n",
            "remote: Compressing objects: 100% (88/88), done.\u001b[K\n",
            "remote: Total 20476 (delta 100), reused 44 (delta 44), pack-reused 20344 (from 4)\u001b[K\n",
            "Receiving objects: 100% (20476/20476), 63.13 MiB | 13.43 MiB/s, done.\n",
            "Resolving deltas: 100% (13618/13618), done.\n",
            "Updating files: 100% (451/451), done.\n",
            "/content/drive/MyDrive/ComfyUI\n",
            "-= Updating ComfyUI =-\n",
            "Already up to date.\n",
            "-= Install dependencies =-\n",
            "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu121, https://download.pytorch.org/whl/cu118, https://download.pytorch.org/whl/cu117\n",
            "Collecting xformers!=0.0.18\n",
            "  Downloading https://download.pytorch.org/whl/cu118/xformers-0.0.30-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\n",
            "Collecting comfyui-frontend-package==1.22.2 (from -r requirements.txt (line 1))\n",
            "  Downloading comfyui_frontend_package-1.22.2-py3-none-any.whl.metadata (117 bytes)\n",
            "Collecting comfyui-workflow-templates==0.1.29 (from -r requirements.txt (line 2))\n",
            "  Downloading comfyui_workflow_templates-0.1.29-py3-none-any.whl.metadata (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.4/55.4 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting comfyui-embedded-docs==0.2.2 (from -r requirements.txt (line 3))\n",
            "  Downloading comfyui_embedded_docs-0.2.2-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (2.6.0+cu124)\n",
            "Collecting torchsde (from -r requirements.txt (line 5))\n",
            "  Downloading torchsde-0.2.6-py3-none-any.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (0.21.0+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (2.6.0+cu124)\n",
            "Requirement already satisfied: numpy>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 8)) (2.0.2)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 9)) (0.8.1)\n",
            "Requirement already satisfied: transformers>=4.28.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 10)) (4.52.4)\n",
            "Requirement already satisfied: tokenizers>=0.13.3 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 11)) (0.21.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 12)) (0.2.0)\n",
            "Requirement already satisfied: safetensors>=0.4.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 13)) (0.5.3)\n",
            "Requirement already satisfied: aiohttp>=3.11.8 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 14)) (3.11.15)\n",
            "Requirement already satisfied: yarl>=1.18.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 15)) (1.20.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 16)) (6.0.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 17)) (11.2.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 18)) (1.15.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 19)) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 20)) (5.9.5)\n",
            "Collecting alembic (from -r requirements.txt (line 21))\n",
            "  Downloading alembic-1.16.2-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: SQLAlchemy in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 22)) (2.0.41)\n",
            "Collecting kornia>=0.7.1 (from -r requirements.txt (line 25))\n",
            "  Downloading kornia-0.8.1-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Collecting spandrel (from -r requirements.txt (line 26))\n",
            "  Downloading spandrel-0.4.1-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 27)) (0.13.1)\n",
            "Collecting av>=14.2.0 (from -r requirements.txt (line 28))\n",
            "  Downloading av-14.4.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: pydantic~=2.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 29)) (2.11.7)\n",
            "Collecting pydantic-settings~=2.0 (from -r requirements.txt (line 30))\n",
            "  Downloading pydantic_settings-2.10.0-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting torch (from -r requirements.txt (line 4))\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torch-2.7.0%2Bcu118-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (28 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 4)) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 4)) (4.14.0)\n",
            "Collecting sympy>=1.13.3 (from torch->-r requirements.txt (line 4))\n",
            "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 4)) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 4)) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 4)) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.8.89 (from torch->-r requirements.txt (line 4))\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.8.89-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu11==11.8.89 (from torch->-r requirements.txt (line 4))\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.8.89-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu11==11.8.87 (from torch->-r requirements.txt (line 4))\n",
            "  Downloading nvidia_cuda_cupti_cu11-11.8.87-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu11==9.1.0.70 (from torch->-r requirements.txt (line 4))\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cudnn_cu11-9.1.0.70-py3-none-manylinux2014_x86_64.whl (663.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m663.9/663.9 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.11.3.6 (from torch->-r requirements.txt (line 4))\n",
            "  Downloading nvidia_cublas_cu11-11.11.3.6-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu11==10.9.0.58 (from torch->-r requirements.txt (line 4))\n",
            "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu11==10.3.0.86 (from torch->-r requirements.txt (line 4))\n",
            "  Downloading nvidia_curand_cu11-10.3.0.86-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu11==11.4.1.48 (from torch->-r requirements.txt (line 4))\n",
            "  Downloading nvidia_cusolver_cu11-11.4.1.48-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu11==11.7.5.86 (from torch->-r requirements.txt (line 4))\n",
            "  Downloading nvidia_cusparse_cu11-11.7.5.86-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-nccl-cu11==2.21.5 (from torch->-r requirements.txt (line 4))\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_nccl_cu11-2.21.5-py3-none-manylinux2014_x86_64.whl (147.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu11==11.8.86 (from torch->-r requirements.txt (line 4))\n",
            "  Downloading nvidia_nvtx_cu11-11.8.86-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==3.3.0 (from torch->-r requirements.txt (line 4))\n",
            "  Downloading https://download.pytorch.org/whl/triton-3.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from triton==3.3.0->torch->-r requirements.txt (line 4)) (75.2.0)\n",
            "Collecting trampoline>=0.1.2 (from torchsde->-r requirements.txt (line 5))\n",
            "  Downloading trampoline-0.1.2-py3-none-any.whl.metadata (10 kB)\n",
            "INFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting torchvision (from -r requirements.txt (line 6))\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.22.1%2Bcu118-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
            "  Downloading torchvision-0.22.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.22.0%2Bcu118-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
            "INFO: pip is looking at multiple versions of torchaudio to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting torchaudio (from -r requirements.txt (line 7))\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.7.1%2Bcu118-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.6 kB)\n",
            "  Downloading torchaudio-2.7.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.6 kB)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.7.0%2Bcu118-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.28.1->-r requirements.txt (line 10)) (0.33.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.28.1->-r requirements.txt (line 10)) (24.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.28.1->-r requirements.txt (line 10)) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers>=4.28.1->-r requirements.txt (line 10)) (2.32.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.11.8->-r requirements.txt (line 14)) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.11.8->-r requirements.txt (line 14)) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.11.8->-r requirements.txt (line 14)) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.11.8->-r requirements.txt (line 14)) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.11.8->-r requirements.txt (line 14)) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.11.8->-r requirements.txt (line 14)) (0.3.2)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.11/dist-packages (from yarl>=1.18.0->-r requirements.txt (line 15)) (3.10)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic->-r requirements.txt (line 21)) (1.1.3)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy->-r requirements.txt (line 22)) (3.2.3)\n",
            "Collecting kornia_rs>=0.1.9 (from kornia>=0.7.1->-r requirements.txt (line 25))\n",
            "  Downloading kornia_rs-0.1.9-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile->-r requirements.txt (line 27)) (1.17.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic~=2.0->-r requirements.txt (line 29)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic~=2.0->-r requirements.txt (line 29)) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic~=2.0->-r requirements.txt (line 29)) (0.4.1)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings~=2.0->-r requirements.txt (line 30))\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile->-r requirements.txt (line 27)) (2.22)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers>=4.28.1->-r requirements.txt (line 10)) (1.1.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch->-r requirements.txt (line 4)) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->-r requirements.txt (line 4)) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.28.1->-r requirements.txt (line 10)) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.28.1->-r requirements.txt (line 10)) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.28.1->-r requirements.txt (line 10)) (2025.6.15)\n",
            "Downloading comfyui_frontend_package-1.22.2-py3-none-any.whl (9.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.3/9.3 MB\u001b[0m \u001b[31m96.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading comfyui_workflow_templates-0.1.29-py3-none-any.whl (71.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.4/71.4 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading comfyui_embedded_docs-0.2.2-py3-none-any.whl (878 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m879.0/879.0 kB\u001b[0m \u001b[31m61.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/cu118/xformers-0.0.30-cp311-cp311-manylinux_2_28_x86_64.whl (16.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m94.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/cu118/torch-2.7.0%2Bcu118-cp311-cp311-manylinux_2_28_x86_64.whl (955.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m955.6/955.6 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu11-11.11.3.6-py3-none-manylinux2014_x86_64.whl (417.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.9/417.9 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu11-11.8.87-py3-none-manylinux2014_x86_64.whl (13.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m127.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu11-11.8.89-py3-none-manylinux2014_x86_64.whl (23.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.2/23.2 MB\u001b[0m \u001b[31m100.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu11-11.8.89-py3-none-manylinux2014_x86_64.whl (875 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m875.6/875.6 kB\u001b[0m \u001b[31m61.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl (168.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu11-10.3.0.86-py3-none-manylinux2014_x86_64.whl (58.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.1/58.1 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu11-11.4.1.48-py3-none-manylinux2014_x86_64.whl (128.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu11-11.7.5.86-py3-none-manylinux2014_x86_64.whl (204.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.1/204.1 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu11-11.8.86-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/triton-3.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (156.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.5/156.5 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchsde-0.2.6-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/cu118/torchvision-0.22.0%2Bcu118-cp311-cp311-manylinux_2_28_x86_64.whl (6.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m76.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/cu118/torchaudio-2.7.0%2Bcu118-cp311-cp311-manylinux_2_28_x86_64.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m67.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.16.2-py3-none-any.whl (242 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.7/242.7 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kornia-0.8.1-py2.py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m75.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading spandrel-0.4.1-py3-none-any.whl (305 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m305.2/305.2 kB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading av-14.4.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.3/35.3 MB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.10.0-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kornia_rs-0.1.9-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m97.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m110.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trampoline-0.1.2-py3-none-any.whl (5.2 kB)\n",
            "Installing collected packages: trampoline, triton, sympy, python-dotenv, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, kornia_rs, comfyui-workflow-templates, comfyui-frontend-package, comfyui-embedded-docs, av, nvidia-cusolver-cu11, nvidia-cudnn-cu11, alembic, torch, pydantic-settings, xformers, torchvision, torchsde, torchaudio, kornia, spandrel\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.2.0\n",
            "    Uninstalling triton-3.2.0:\n",
            "      Successfully uninstalled triton-3.2.0\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.13.1\n",
            "    Uninstalling sympy-1.13.1:\n",
            "      Successfully uninstalled sympy-1.13.1\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.6.0+cu124\n",
            "    Uninstalling torch-2.6.0+cu124:\n",
            "      Successfully uninstalled torch-2.6.0+cu124\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.21.0+cu124\n",
            "    Uninstalling torchvision-0.21.0+cu124:\n",
            "      Successfully uninstalled torchvision-0.21.0+cu124\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 2.6.0+cu124\n",
            "    Uninstalling torchaudio-2.6.0+cu124:\n",
            "      Successfully uninstalled torchaudio-2.6.0+cu124\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "fastai 2.7.19 requires torch<2.7,>=1.10, but you have torch 2.7.0+cu118 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed alembic-1.16.2 av-14.4.0 comfyui-embedded-docs-0.2.2 comfyui-frontend-package-1.22.2 comfyui-workflow-templates-0.1.29 kornia-0.8.1 kornia_rs-0.1.9 nvidia-cublas-cu11-11.11.3.6 nvidia-cuda-cupti-cu11-11.8.87 nvidia-cuda-nvrtc-cu11-11.8.89 nvidia-cuda-runtime-cu11-11.8.89 nvidia-cudnn-cu11-9.1.0.70 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.3.0.86 nvidia-cusolver-cu11-11.4.1.48 nvidia-cusparse-cu11-11.7.5.86 nvidia-nccl-cu11-2.21.5 nvidia-nvtx-cu11-11.8.86 pydantic-settings-2.10.0 python-dotenv-1.1.0 spandrel-0.4.1 sympy-1.14.0 torch-2.7.0+cu118 torchaudio-2.7.0+cu118 torchsde-0.2.6 torchvision-0.22.0+cu118 trampoline-0.1.2 triton-3.3.0 xformers-0.0.30\n"
          ]
        }
      ],
      "source": [
        "#@title Environment Setup\n",
        "\n",
        "\n",
        "OPTIONS = {}\n",
        "\n",
        "USE_GOOGLE_DRIVE = True  #@param {type:\"boolean\"}\n",
        "UPDATE_COMFY_UI = True  #@param {type:\"boolean\"}\n",
        "WORKSPACE = 'ComfyUI'\n",
        "OPTIONS['USE_GOOGLE_DRIVE'] = USE_GOOGLE_DRIVE\n",
        "OPTIONS['UPDATE_COMFY_UI'] = UPDATE_COMFY_UI\n",
        "\n",
        "if OPTIONS['USE_GOOGLE_DRIVE']:\n",
        "    !echo \"Mounting Google Drive...\"\n",
        "    %cd /\n",
        "\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    WORKSPACE = \"/content/drive/MyDrive/ComfyUI\"\n",
        "    %cd /content/drive/MyDrive\n",
        "\n",
        "![ ! -d $WORKSPACE ] && echo -= Initial setup ComfyUI =- && git clone https://github.com/comfyanonymous/ComfyUI\n",
        "%cd $WORKSPACE\n",
        "\n",
        "if OPTIONS['UPDATE_COMFY_UI']:\n",
        "  !echo -= Updating ComfyUI =-\n",
        "  !git pull\n",
        "\n",
        "!echo -= Install dependencies =-\n",
        "!pip install xformers!=0.0.18 -r requirements.txt --extra-index-url https://download.pytorch.org/whl/cu121 --extra-index-url https://download.pytorch.org/whl/cu118 --extra-index-url https://download.pytorch.org/whl/cu117"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cccccccccc"
      },
      "source": [
        "Download some models/checkpoints/vae or custom comfyui nodes (uncomment the commands for the ones you want)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "dddddddddd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2843480d-95bc-4b11-ad0b-5dbef550fc9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "animagine-xl-3.1.safetensors already exists. Skipping.\n",
            "sdxl_vae.safetensors already exists. Skipping.\n",
            "sd_xl_offset_example-lora_1.0.safetensors already exists. Skipping.\n",
            "control_v11p_sd15_openpose_fp16.safetensors already exists. Skipping.\n",
            "control_v11p_sd15s2_lineart_anime_fp16.safetensors already exists. Skipping.\n",
            "control_v11f1p_sd15_depth_fp16.safetensors already exists. Skipping.\n",
            "RealESRGAN_x4plus.pth already exists. Skipping.\n",
            "Downloading real-esrgan-x4-anime-6b.pth...\n",
            "/content/ComfyUI\n",
            "Installing dependencies...\n",
            "Cloning ControlNet Preprocessors...\n",
            "Created config file at: /content/ComfyUI/extra_model_paths.yaml with correct format.\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# STEP 1: Connect to your permanent storage (Google Drive)\n",
        "# ==============================================================================\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# ==============================================================================\n",
        "# STEP 2: Download Models to Google Drive (if they don't exist)\n",
        "# ==============================================================================\n",
        "import os\n",
        "\n",
        "# Define the base path on your Google Drive for all AI assets\n",
        "drive_base_path = \"/content/drive/MyDrive/AI_Manhwa_Studio\"\n",
        "models_path = os.path.join(drive_base_path, \"models\")\n",
        "\n",
        "# Define full paths for each model type\n",
        "checkpoint_path = os.path.join(models_path, \"checkpoints\")\n",
        "vae_path = os.path.join(models_path, \"vae\")\n",
        "lora_path = os.path.join(models_path, \"loras\")\n",
        "controlnet_path = os.path.join(models_path, \"controlnet\")\n",
        "upscale_path = os.path.join(models_path, \"upscale_models\")\n",
        "\n",
        "# Create directories if they don't exist\n",
        "for path in [checkpoint_path, vae_path, lora_path, controlnet_path, upscale_path]:\n",
        "    os.makedirs(path, exist_ok=True)\n",
        "\n",
        "# Helper function to download files\n",
        "def download_if_not_exists(url, dest_folder):\n",
        "    filename = url.split('/')[-1]\n",
        "    dest_path = os.path.join(dest_folder, filename)\n",
        "    if not os.path.exists(dest_path):\n",
        "        print(f\"Downloading {filename}...\")\n",
        "        os.system(f\"wget -c '{url}' -P '{dest_folder}'\")\n",
        "    else:\n",
        "        print(f\"{filename} already exists. Skipping.\")\n",
        "\n",
        "# --- Download all your models as before ---\n",
        "download_if_not_exists(\"https://huggingface.co/cagliostrolab/animagine-xl-3.1/resolve/main/animagine-xl-3.1.safetensors\", checkpoint_path)\n",
        "download_if_not_exists(\"https://huggingface.co/stabilityai/sdxl-vae/resolve/main/sdxl_vae.safetensors\", vae_path)\n",
        "download_if_not_exists(\"https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/resolve/main/sd_xl_offset_example-lora_1.0.safetensors\", lora_path)\n",
        "download_if_not_exists(\"https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_openpose_fp16.safetensors\", controlnet_path)\n",
        "download_if_not_exists(\"https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15s2_lineart_anime_fp16.safetensors\", controlnet_path)\n",
        "download_if_not_exists(\"https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11f1p_sd15_depth_fp16.safetensors\", controlnet_path)\n",
        "download_if_not_exists(\"https://github.com/xinntao/Real-ESRGAN/releases/download/v0.1.0/RealESRGAN_x4plus.pth\", upscale_path)\n",
        "download_if_not_exists(\"https://huggingface.co/uwg/real-esrgan-x4-anime-6b/resolve/main/real-esrgan-x4-anime-6b.pth\", upscale_path)\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# STEP 3: Install ComfyUI and its Dependencies\n",
        "# ==============================================================================\n",
        "import os\n",
        "comfyui_path = \"/content/ComfyUI\"\n",
        "\n",
        "if not os.path.exists(comfyui_path):\n",
        "    print(\"Cloning ComfyUI repository...\")\n",
        "    os.system(f\"git clone https://github.com/comfyanonymous/ComfyUI.git {comfyui_path}\")\n",
        "\n",
        "%cd {comfyui_path}\n",
        "print(\"Installing dependencies...\")\n",
        "os.system(\"pip install -r requirements.txt\")\n",
        "\n",
        "# Install the essential ControlNet Preprocessor nodes\n",
        "preprocessor_path = os.path.join(comfyui_path, \"custom_nodes/comfy_controlnet_preprocessors\")\n",
        "if not os.path.exists(preprocessor_path):\n",
        "    print(\"Cloning ControlNet Preprocessors...\")\n",
        "    os.system(f\"git clone https://github.com/Fannovel16/comfy_controlnet_preprocessors {preprocessor_path}\")\n",
        "    os.system(f\"cd {preprocessor_path} && python install.py\")\n",
        "else:\n",
        "    print(\"ControlNet Preprocessors already exist.\")\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# STEP 4: Create the Configuration File to Link Your Drive\n",
        "# ==============================================================================\n",
        "import yaml\n",
        "\n",
        "config_data = {\n",
        "    'other_ui': {\n",
        "        'base_path': models_path\n",
        "    }\n",
        "}\n",
        "\n",
        "config_file_path = os.path.join(comfyui_path, \"extra_model_paths.yaml\")\n",
        "with open(config_file_path, 'w') as f:\n",
        "    yaml.dump(config_data, f)\n",
        "print(f\"Created config file at: {config_file_path} with correct format.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkkkkkkkkkkkkkk"
      },
      "source": [
        "### Run ComfyUI with cloudflared (Recommended Way)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jjjjjjjjjjjjjj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "outputId": "dcd5eebd-cf75-4eb3-a0f0-1f90bd274c03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint files will always be loaded safely.\n",
            "Total VRAM 15095 MB, total RAM 12978 MB\n",
            "pytorch version: 2.7.0+cu118\n",
            "xformers version: 0.0.30\n",
            "Set vram state to: NORMAL_VRAM\n",
            "Device: cuda:0 Tesla T4 : cudaMallocAsync\n",
            "Using xformers attention\n",
            "Python version: 3.11.13 (main, Jun  4 2025, 08:57:29) [GCC 11.4.0]\n",
            "ComfyUI version: 0.3.41\n",
            "ComfyUI frontend version: 1.22.2\n",
            "[Prompt Server] web root: /usr/local/lib/python3.11/dist-packages/comfyui_frontend_package/static\n",
            "\n",
            "Import times for custom nodes:\n",
            "   0.0 seconds: /content/ComfyUI/custom_nodes/websocket_image_save.py\n",
            "\n",
            "Context impl SQLiteImpl.\n",
            "Will assume non-transactional DDL.\n",
            "No target revision found.\n",
            "to open it in a new window you can open this link here:\n",
            "\u001b[31mWarning: This function may stop working due to changes in browser security.\n",
            "Try `serve_kernel_port_as_iframe` instead. \u001b[0m\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, text, element) => {\n",
              "    if (!google.colab.kernel.accessAllowed) {\n",
              "      return;\n",
              "    }\n",
              "    element.appendChild(document.createTextNode(''));\n",
              "    const url = await google.colab.kernel.proxyPort(port);\n",
              "    const anchor = document.createElement('a');\n",
              "    anchor.href = new URL(path, url).toString();\n",
              "    anchor.target = '_blank';\n",
              "    anchor.setAttribute('data-href', url + path);\n",
              "    anchor.textContent = text;\n",
              "    element.appendChild(anchor);\n",
              "  })(8188, \"/\", \"https://localhost:8188/\", window.element)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "got prompt\n",
            "invalid prompt: {'type': 'prompt_no_outputs', 'message': 'Prompt has no outputs', 'details': '', 'extra_info': {}}\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# CELL 2: LAUNCH COMFYUI AND DISPLAY IN NOTEBOOK\n",
        "# ==============================================================================\n",
        "import threading\n",
        "import time\n",
        "import socket\n",
        "from google.colab import output\n",
        "\n",
        "# This function waits for the ComfyUI server to be ready and then displays it\n",
        "def iframe_thread(port):\n",
        "  # Wait until the port is open\n",
        "  while True:\n",
        "      time.sleep(0.5)\n",
        "      sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "      result = sock.connect_ex(('127.0.0.1', port))\n",
        "      if result == 0:\n",
        "        break\n",
        "      sock.close()\n",
        "\n",
        "\n",
        "  print(\"to open it in a new window you can open this link here:\")\n",
        "  output.serve_kernel_port_as_window(port)\n",
        "\n",
        "# Start the thread that will display the UI\n",
        "# We run this in the background so it can wait for the server to start\n",
        "threading.Thread(target=iframe_thread, daemon=True, args=(8188,)).start()\n",
        "\n",
        "# Launch ComfyUI\n",
        "# The --dont-print-server argument keeps the log clean\n",
        "# It will run in this cell until you stop it\n",
        "!python main.py --dont-print-server"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkkkkkkkkkkkkk"
      },
      "source": [
        "### Run ComfyUI with localtunnel\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "jjjjjjjjjjjjj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98617772-c0df-4df9-dbfb-96c1401b32ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K\n",
            "added 22 packages in 3s\n",
            "\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K\n",
            "\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K3 packages are looking for funding\n",
            "\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K  run `npm fund` for details\n",
            "\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0KCheckpoint files will always be loaded safely.\n",
            "Total VRAM 15095 MB, total RAM 12978 MB\n",
            "pytorch version: 2.7.0+cu118\n",
            "xformers version: 0.0.30\n",
            "Set vram state to: NORMAL_VRAM\n",
            "Device: cuda:0 Tesla T4 : cudaMallocAsync\n",
            "Using xformers attention\n",
            "Python version: 3.11.13 (main, Jun  4 2025, 08:57:29) [GCC 11.4.0]\n",
            "ComfyUI version: 0.3.41\n",
            "ComfyUI frontend version: 1.22.2\n",
            "[Prompt Server] web root: /usr/local/lib/python3.11/dist-packages/comfyui_frontend_package/static\n",
            "\n",
            "Import times for custom nodes:\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/websocket_image_save.py\n",
            "\n",
            "Context impl SQLiteImpl.\n",
            "Will assume non-transactional DDL.\n",
            "No target revision found.\n",
            "\n",
            "ComfyUI finished loading, trying to launch localtunnel (if it gets stuck here localtunnel is having issues)\n",
            "\n",
            "The password/enpoint ip for localtunnel is: 35.197.25.86\n",
            "your url is: https://slimy-windows-camp.loca.lt\n",
            "got prompt\n",
            "Failed to validate prompt for output 9:\n",
            "* CheckpointLoaderSimple 4:\n",
            "  - Value not in list: ckpt_name: 'sd3.5_large_fp8_scaled.safetensors' not in ['animagine-xl-3.1.safetensors']\n",
            "Output will be ignored\n",
            "invalid prompt: {'type': 'prompt_outputs_failed_validation', 'message': 'Prompt outputs failed validation', 'details': '', 'extra_info': {}}\n",
            "got prompt\n",
            "invalid prompt: {'type': 'prompt_no_outputs', 'message': 'Prompt has no outputs', 'details': '', 'extra_info': {}}\n",
            "got prompt\n",
            "Failed to validate prompt for output 1:\n",
            "* (prompt):\n",
            "  - Required input is missing: images\n",
            "* SaveImage 1:\n",
            "  - Required input is missing: images\n",
            "Output will be ignored\n",
            "invalid prompt: {'type': 'prompt_outputs_failed_validation', 'message': 'Prompt outputs failed validation', 'details': 'Required input is missing: images', 'extra_info': {}}\n",
            "got prompt\n",
            "Failed to validate prompt for output 1:\n",
            "* ImageBatch 4:\n",
            "  - Required input is missing: image2\n",
            "  - Required input is missing: image1\n",
            "Output will be ignored\n",
            "invalid prompt: {'type': 'prompt_outputs_failed_validation', 'message': 'Prompt outputs failed validation', 'details': '', 'extra_info': {}}\n",
            "got prompt\n",
            "Failed to validate prompt for output 9:\n",
            "* CheckpointLoaderSimple 4:\n",
            "  - Value not in list: ckpt_name: 'v1-5-pruned-emaonly-fp16.safetensors' not in ['animagine-xl-3.1.safetensors']\n",
            "Output will be ignored\n",
            "invalid prompt: {'type': 'prompt_outputs_failed_validation', 'message': 'Prompt outputs failed validation', 'details': '', 'extra_info': {}}\n",
            "got prompt\n",
            "model weight dtype torch.float16, manual cast: None\n",
            "model_type EPS\n",
            "got prompt\n",
            "Using xformers attention in VAE\n",
            "Using xformers attention in VAE\n",
            "VAE load device: cuda:0, offload device: cpu, dtype: torch.float32\n",
            "Requested to load SDXLClipModel\n",
            "loaded completely 9.5367431640625e+25 1560.802734375 True\n",
            "CLIP/text encoder model load device: cuda:0, offload device: cpu, current: cuda:0, dtype: torch.float16\n",
            "loaded diffusion model directly to GPU\n",
            "Requested to load SDXL\n",
            "loaded completely 9.5367431640625e+25 4897.0483474731445 True\n",
            "100% 20/20 [00:05<00:00,  3.76it/s]\n",
            "Requested to load AutoencoderKL\n",
            "loaded completely 5896.100997924805 319.11416244506836 True\n",
            "Prompt executed in 43.92 seconds\n",
            "100% 20/20 [00:04<00:00,  4.61it/s]\n",
            "Prompt executed in 5.03 seconds\n",
            "got prompt\n",
            "100% 20/20 [00:04<00:00,  4.57it/s]\n",
            "Prompt executed in 5.11 seconds\n",
            "got prompt\n",
            " 70% 14/20 [00:02<00:01,  4.54it/s]got prompt\n",
            "100% 20/20 [00:04<00:00,  4.65it/s]\n",
            "Prompt executed in 5.11 seconds\n",
            " 90% 18/20 [00:03<00:00,  4.42it/s]got prompt\n",
            "100% 20/20 [00:04<00:00,  4.50it/s]\n",
            "Prompt executed in 5.14 seconds\n",
            "100% 20/20 [00:04<00:00,  4.40it/s]\n",
            "Prompt executed in 5.26 seconds\n",
            "got prompt\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (105 > 77). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (105 > 77). Running this sequence through the model will result in indexing errors\n",
            "100% 20/20 [00:04<00:00,  4.56it/s]\n",
            "Prompt executed in 5.35 seconds\n",
            "got prompt\n",
            "100% 20/20 [00:04<00:00,  4.41it/s]\n",
            "Prompt executed in 5.24 seconds\n",
            "got prompt\n",
            "100% 20/20 [00:04<00:00,  4.31it/s]\n",
            "Prompt executed in 5.35 seconds\n",
            "got prompt\n",
            "100% 40/40 [00:23<00:00,  1.69it/s]\n",
            "Prompt executed in 25.48 seconds\n",
            "got prompt\n",
            "Prompt executed in 0.00 seconds\n",
            "got prompt\n",
            "Prompt executed in 0.00 seconds\n",
            "got prompt\n",
            "Prompt executed in 0.00 seconds\n",
            "got prompt\n",
            "Prompt executed in 0.00 seconds\n",
            "got prompt\n",
            "Prompt executed in 0.00 seconds\n",
            "got prompt\n",
            "100% 40/40 [00:22<00:00,  1.75it/s]\n",
            "Prompt executed in 24.65 seconds\n",
            "got prompt\n",
            "100% 40/40 [00:23<00:00,  1.70it/s]\n",
            "Prompt executed in 25.50 seconds\n",
            "got prompt\n",
            "100% 40/40 [00:23<00:00,  1.73it/s]\n",
            "Prompt executed in 24.91 seconds\n",
            "\n",
            "Stopped server\n",
            "Exception ignored in atexit callback: <function dump_compile_times at 0x7fb998442980>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/utils.py\", line 765, in dump_compile_times\n",
            "    log.info(compile_times(repr=\"str\", aggregate=True))\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/utils.py\", line 751, in compile_times\n",
            "    out += tabulate(rows, headers=(\"Function\", \"Runtimes (s)\"))\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/utils.py\", line 217, in tabulate\n",
            "    import tabulate\n",
            "  File \"<frozen importlib._bootstrap>\", line 1176, in _find_and_load\n",
            "  File \"<frozen importlib._bootstrap>\", line 1147, in _find_and_load_unlocked\n",
            "  File \"<frozen importlib._bootstrap>\", line 690, in _load_unlocked\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 936, in exec_module\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 1032, in get_code\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 1131, in get_data\n",
            "KeyboardInterrupt: \n"
          ]
        }
      ],
      "source": [
        "!npm install -g localtunnel\n",
        "\n",
        "import threading\n",
        "\n",
        "def iframe_thread(port):\n",
        "  while True:\n",
        "      time.sleep(0.5)\n",
        "      sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "      result = sock.connect_ex(('127.0.0.1', port))\n",
        "      if result == 0:\n",
        "        break\n",
        "      sock.close()\n",
        "  print(\"\\nComfyUI finished loading, trying to launch localtunnel (if it gets stuck here localtunnel is having issues)\\n\")\n",
        "\n",
        "  print(\"The password/enpoint ip for localtunnel is:\", urllib.request.urlopen('https://ipv4.icanhazip.com').read().decode('utf8').strip(\"\\n\"))\n",
        "  p = subprocess.Popen([\"lt\", \"--port\", \"{}\".format(port)], stdout=subprocess.PIPE)\n",
        "  for line in p.stdout:\n",
        "    print(line.decode(), end='')\n",
        "\n",
        "\n",
        "threading.Thread(target=iframe_thread, daemon=True, args=(8188,)).start()\n",
        "\n",
        "!python main.py --dont-print-server"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gggggggggg"
      },
      "source": [
        "### Run ComfyUI with colab iframe (use only in case the previous way with localtunnel doesn't work)\n",
        "\n",
        "You should see the ui appear in an iframe. If you get a 403 error, it's your firefox settings or an extension that's messing things up.\n",
        "\n",
        "If you want to open it in another window use the link.\n",
        "\n",
        "Note that some UI features like live image previews won't work because the colab iframe blocks websockets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hhhhhhhhhh"
      },
      "outputs": [],
      "source": [
        "import threading\n",
        "def iframe_thread(port):\n",
        "  while True:\n",
        "      time.sleep(0.5)\n",
        "      sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "      result = sock.connect_ex(('127.0.0.1', port))\n",
        "      if result == 0:\n",
        "        break\n",
        "      sock.close()\n",
        "  from google.colab import output\n",
        "  output.serve_kernel_port_as_iframe(port, height=1024)\n",
        "  print(\"to open it in a window you can open this link here:\")\n",
        "  output.serve_kernel_port_as_window(port)\n",
        "\n",
        "threading.Thread(target=iframe_thread, daemon=True, args=(8188,)).start()\n",
        "\n",
        "!python main.py --dont-print-server"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}